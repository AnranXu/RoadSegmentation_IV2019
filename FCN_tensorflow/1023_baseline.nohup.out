Step: 0, Train_loss:179.565
2018-10-23 21:51:12.713609 ---> Validation_loss: 158.343
Step: 100, Train_loss:8.51359
Step: 200, Train_loss:1.59539
Step: 300, Train_loss:1.15263
Step: 400, Train_loss:0.71261
Step: 500, Train_loss:0.601513
Step: 600, Train_loss:0.695782
Step: 700, Train_loss:0.460001
Step: 800, Train_loss:0.540343
Step: 900, Train_loss:0.639722
Step: 1000, Train_loss:0.442371
Step: 1100, Train_loss:0.370753
Step: 1200, Train_loss:0.439832
Step: 1300, Train_loss:0.355432
Step: 1400, Train_loss:0.539966
Step: 1500, Train_loss:0.360577
Step: 1600, Train_loss:0.451159
Step: 1700, Train_loss:0.448086
Step: 1800, Train_loss:0.405866
Step: 1900, Train_loss:0.389994
Step: 2000, Train_loss:0.355849
Step: 2100, Train_loss:0.318515
Step: 2200, Train_loss:0.306574
Step: 2300, Train_loss:0.393723
Step: 2400, Train_loss:0.340689
Step: 2500, Train_loss:0.323493
Step: 2600, Train_loss:0.408362
Step: 2700, Train_loss:0.388336
Step: 2800, Train_loss:0.409397
Step: 2900, Train_loss:0.297304
Step: 3000, Train_loss:0.31619
Step: 3100, Train_loss:0.35694
Step: 3200, Train_loss:0.464452
Step: 3300, Train_loss:0.374847
Step: 3400, Train_loss:0.314446
Step: 3500, Train_loss:0.358233
Step: 3600, Train_loss:0.444477
Step: 3700, Train_loss:0.252603
Step: 3800, Train_loss:0.450738
Step: 3900, Train_loss:0.391065
Step: 4000, Train_loss:0.311583
Step: 4100, Train_loss:0.343656
Step: 4200, Train_loss:0.280979
Step: 4300, Train_loss:0.304001
Step: 4400, Train_loss:0.261588
Step: 4500, Train_loss:0.328561
Step: 4600, Train_loss:0.315289
Step: 4700, Train_loss:0.249533
Step: 4800, Train_loss:0.273371
Step: 4900, Train_loss:0.253141
Step: 5000, Train_loss:0.368129
2018-10-23 22:18:36.576713 ---> Validation_loss: 0.277601
Step: 5100, Train_loss:0.298119
Step: 5200, Train_loss:0.253473
Step: 5300, Train_loss:0.293216
Step: 5400, Train_loss:0.327219
Step: 5500, Train_loss:0.285465
Step: 5600, Train_loss:0.293525
Step: 5700, Train_loss:0.368699
Step: 5800, Train_loss:0.279493
Step: 5900, Train_loss:0.307328
Step: 6000, Train_loss:0.32796
Step: 6100, Train_loss:0.258419
Step: 6200, Train_loss:0.214175
Step: 6300, Train_loss:0.264129
Step: 6400, Train_loss:0.307977
Step: 6500, Train_loss:0.31662
Step: 6600, Train_loss:0.233878
Step: 6700, Train_loss:0.304545
Step: 6800, Train_loss:0.367144
Step: 6900, Train_loss:0.266669
Step: 7000, Train_loss:0.247444
Step: 7100, Train_loss:0.242533
Step: 7200, Train_loss:0.330755
Step: 7300, Train_loss:0.31061
Step: 7400, Train_loss:0.253379
Step: 7500, Train_loss:0.296737
Step: 7600, Train_loss:0.270188
Step: 7700, Train_loss:0.297716
Step: 7800, Train_loss:0.276538
****************** Epochs completed: 10******************
Step: 7900, Train_loss:0.304298
Step: 8000, Train_loss:0.281705
Step: 8100, Train_loss:0.388617
Step: 8200, Train_loss:0.304587
Step: 8300, Train_loss:0.275923
Step: 8400, Train_loss:0.283567
Step: 8500, Train_loss:0.293465
Step: 8600, Train_loss:0.256817
Step: 8700, Train_loss:0.249494
Step: 8800, Train_loss:0.212285
Step: 8900, Train_loss:0.290425
Step: 9000, Train_loss:0.278939
Step: 9100, Train_loss:0.297999
Step: 9200, Train_loss:0.242932
Step: 9300, Train_loss:0.244986
Step: 9400, Train_loss:0.253327
Step: 9500, Train_loss:0.361236
Step: 9600, Train_loss:0.269168
Step: 9700, Train_loss:0.231138
Step: 9800, Train_loss:0.317236
Step: 9900, Train_loss:0.224299
Step: 10000, Train_loss:0.300273
2018-10-23 22:45:52.629192 ---> Validation_loss: 0.246902
Step: 10100, Train_loss:0.306077
Step: 10200, Train_loss:0.272435
Step: 10300, Train_loss:0.214788
Step: 10400, Train_loss:0.221539
Step: 10500, Train_loss:0.246617
Step: 10600, Train_loss:0.342381
Step: 10700, Train_loss:0.288499
Step: 10800, Train_loss:0.274666
Step: 10900, Train_loss:0.22432
Step: 11000, Train_loss:0.27202
Step: 11100, Train_loss:0.291721
Step: 11200, Train_loss:0.259398
Step: 11300, Train_loss:0.249515
Step: 11400, Train_loss:0.248013
Step: 11500, Train_loss:0.232767
Step: 11600, Train_loss:0.222785
Step: 11700, Train_loss:0.237691
Step: 11800, Train_loss:0.231042
Step: 11900, Train_loss:0.210759
Step: 12000, Train_loss:0.23039
Step: 12100, Train_loss:0.229397
Step: 12200, Train_loss:0.277339
Step: 12300, Train_loss:0.269631
Step: 12400, Train_loss:0.322498
Step: 12500, Train_loss:0.231226
Step: 12600, Train_loss:0.269303
Step: 12700, Train_loss:0.229585
Step: 12800, Train_loss:0.248639
Step: 12900, Train_loss:0.316537
Step: 13000, Train_loss:0.22918
Step: 13100, Train_loss:0.266696
Step: 13200, Train_loss:0.201453
Step: 13300, Train_loss:0.275237
Step: 13400, Train_loss:0.275934
Step: 13500, Train_loss:0.26678
Step: 13600, Train_loss:0.211113
Step: 13700, Train_loss:0.302385
Step: 13800, Train_loss:0.259188
Step: 13900, Train_loss:0.265995
Step: 14000, Train_loss:0.2271
Step: 14100, Train_loss:0.236974
Step: 14200, Train_loss:0.262813
Step: 14300, Train_loss:0.28504
Step: 14400, Train_loss:0.20745
Step: 14500, Train_loss:0.224415
Step: 14600, Train_loss:0.236612
Step: 14700, Train_loss:0.305495
Step: 14800, Train_loss:0.224379
Step: 14900, Train_loss:0.246169
Step: 15000, Train_loss:0.336957
2018-10-23 23:13:06.587949 ---> Validation_loss: 0.247235
Step: 15100, Train_loss:0.246864
Step: 15200, Train_loss:0.263988
Step: 15300, Train_loss:0.272929
Step: 15400, Train_loss:0.228475
Step: 15500, Train_loss:0.289107
Step: 15600, Train_loss:0.267238
****************** Epochs completed: 20******************
Step: 15700, Train_loss:0.218752
Step: 15800, Train_loss:0.225107
Step: 15900, Train_loss:0.256247
Step: 16000, Train_loss:0.258773
Step: 16100, Train_loss:0.275676
Step: 16200, Train_loss:0.232615
Step: 16300, Train_loss:0.206958
Step: 16400, Train_loss:0.318192
Step: 16500, Train_loss:0.27138
Step: 16600, Train_loss:0.275126
Step: 16700, Train_loss:0.227154
Step: 16800, Train_loss:0.283461
Step: 16900, Train_loss:0.271971
Step: 17000, Train_loss:0.267461
Step: 17100, Train_loss:0.213814
Step: 17200, Train_loss:0.300793
Step: 17300, Train_loss:0.274622
Step: 17400, Train_loss:0.213801
Step: 17500, Train_loss:0.22269
Step: 17600, Train_loss:0.309839
Step: 17700, Train_loss:0.24704
Step: 17800, Train_loss:0.232038
Step: 17900, Train_loss:0.228743
Step: 18000, Train_loss:0.256734
Step: 18100, Train_loss:0.24515
Step: 18200, Train_loss:0.271513
Step: 18300, Train_loss:0.225237
Step: 18400, Train_loss:0.227176
Step: 18500, Train_loss:0.251629
Step: 18600, Train_loss:0.243179
Step: 18700, Train_loss:0.218315
Step: 18800, Train_loss:0.295562
Step: 18900, Train_loss:0.210063
Step: 19000, Train_loss:0.238074
Step: 19100, Train_loss:0.254431
Step: 19200, Train_loss:0.243131
Step: 19300, Train_loss:0.252429
Step: 19400, Train_loss:0.220025
Step: 19500, Train_loss:0.219112
Step: 19600, Train_loss:0.211101
Step: 19700, Train_loss:0.21486
Step: 19800, Train_loss:0.212068
Step: 19900, Train_loss:0.289405
Step: 20000, Train_loss:0.225968
2018-10-23 23:40:24.051562 ---> Validation_loss: 0.234138
Step: 20100, Train_loss:0.284934
Step: 20200, Train_loss:0.218188
Step: 20300, Train_loss:0.248523
Step: 20400, Train_loss:0.211525
Step: 20500, Train_loss:0.257946
Step: 20600, Train_loss:0.264333
Step: 20700, Train_loss:0.250503
Step: 20800, Train_loss:0.292518
Step: 20900, Train_loss:0.219306
Step: 21000, Train_loss:0.265111
Step: 21100, Train_loss:0.21123
Step: 21200, Train_loss:0.225109
Step: 21300, Train_loss:0.212657
Step: 21400, Train_loss:0.21274
Step: 21500, Train_loss:0.242961
Step: 21600, Train_loss:0.217975
Step: 21700, Train_loss:0.260393
Step: 21800, Train_loss:0.294102
Step: 21900, Train_loss:0.24423
Step: 22000, Train_loss:0.236944
Step: 22100, Train_loss:0.226923
Step: 22200, Train_loss:0.210066
Step: 22300, Train_loss:0.282326
Step: 22400, Train_loss:0.244519
Step: 22500, Train_loss:0.239199
Step: 22600, Train_loss:0.233596
Step: 22700, Train_loss:0.230759
Step: 22800, Train_loss:0.221904
Step: 22900, Train_loss:0.240982
Step: 23000, Train_loss:0.245758
Step: 23100, Train_loss:0.247387
Step: 23200, Train_loss:0.219113
Step: 23300, Train_loss:0.213794
Step: 23400, Train_loss:0.209892
Step: 23500, Train_loss:0.203154
****************** Epochs completed: 30******************
Step: 23600, Train_loss:0.196096
Step: 23700, Train_loss:0.253493
Step: 23800, Train_loss:0.246768
Step: 23900, Train_loss:0.223757
Step: 24000, Train_loss:0.230262
Step: 24100, Train_loss:0.189953
Step: 24200, Train_loss:0.246534
Step: 24300, Train_loss:0.193246
Step: 24400, Train_loss:0.237442
Step: 24500, Train_loss:0.292805
Step: 24600, Train_loss:0.300195
Step: 24700, Train_loss:0.246632
Step: 24800, Train_loss:0.260216
Step: 24900, Train_loss:0.20161
Step: 25000, Train_loss:0.225471
2018-10-24 00:07:38.966562 ---> Validation_loss: 0.235735
Step: 25100, Train_loss:0.226946
Step: 25200, Train_loss:0.195354
Step: 25300, Train_loss:0.214126
Step: 25400, Train_loss:0.198679
Step: 25500, Train_loss:0.24487
Step: 25600, Train_loss:0.298924
Step: 25700, Train_loss:0.202842
Step: 25800, Train_loss:0.233703
Step: 25900, Train_loss:0.239223
Step: 26000, Train_loss:0.205718
Step: 26100, Train_loss:0.196713
Step: 26200, Train_loss:0.196539
Step: 26300, Train_loss:0.239112
Step: 26400, Train_loss:0.188995
Step: 26500, Train_loss:0.221171
Step: 26600, Train_loss:0.233856
Step: 26700, Train_loss:0.247178
Step: 26800, Train_loss:0.192803
Step: 26900, Train_loss:0.215533
Step: 27000, Train_loss:0.211337
Step: 27100, Train_loss:0.23578
Step: 27200, Train_loss:0.160371
Step: 27300, Train_loss:0.208697
Step: 27400, Train_loss:0.208021
Step: 27500, Train_loss:0.200897
Step: 27600, Train_loss:0.201199
Step: 27700, Train_loss:0.20106
Step: 27800, Train_loss:0.248497
Step: 27900, Train_loss:0.180776
Step: 28000, Train_loss:0.22066
Step: 28100, Train_loss:0.238498
Step: 28200, Train_loss:0.308927
Step: 28300, Train_loss:0.215207
Step: 28400, Train_loss:0.21307
Step: 28500, Train_loss:0.19194
Step: 28600, Train_loss:0.190805
Step: 28700, Train_loss:0.194068
Step: 28800, Train_loss:0.222144
Step: 28900, Train_loss:0.226513
Step: 29000, Train_loss:0.193079
Step: 29100, Train_loss:0.188121
Step: 29200, Train_loss:0.202408
Step: 29300, Train_loss:0.226276
Step: 29400, Train_loss:0.194874
Step: 29500, Train_loss:0.220795
Step: 29600, Train_loss:0.210878
Step: 29700, Train_loss:0.200156
Step: 29800, Train_loss:0.182981
Step: 29900, Train_loss:0.229348
Step: 30000, Train_loss:0.251799
2018-10-24 00:34:54.794931 ---> Validation_loss: 0.245547
Step: 30100, Train_loss:0.191205
Step: 30200, Train_loss:0.201084
Step: 30300, Train_loss:0.23836
Step: 30400, Train_loss:0.225933
Step: 30500, Train_loss:0.216463
Step: 30600, Train_loss:0.19861
Step: 30700, Train_loss:0.192241
Step: 30800, Train_loss:0.201695
Step: 30900, Train_loss:0.232954
Step: 31000, Train_loss:0.216566
Step: 31100, Train_loss:0.244932
Step: 31200, Train_loss:0.185466
Step: 31300, Train_loss:0.220218
****************** Epochs completed: 40******************
Step: 31400, Train_loss:0.21214
Step: 31500, Train_loss:0.195803
Step: 31600, Train_loss:0.149361
Step: 31700, Train_loss:0.231943
Step: 31800, Train_loss:0.186439
Step: 31900, Train_loss:0.216348
Step: 32000, Train_loss:0.203968
Step: 32100, Train_loss:0.224232
Step: 32200, Train_loss:0.186091
Step: 32300, Train_loss:0.175387
Step: 32400, Train_loss:0.19299
Step: 32500, Train_loss:0.194158
Step: 32600, Train_loss:0.197047
Step: 32700, Train_loss:0.182776
Step: 32800, Train_loss:0.223379
Step: 32900, Train_loss:0.240903
Step: 33000, Train_loss:0.250106
Step: 33100, Train_loss:0.224736
Step: 33200, Train_loss:0.186453
Step: 33300, Train_loss:0.221691
Step: 33400, Train_loss:0.209916
Step: 33500, Train_loss:0.221337
Step: 33600, Train_loss:0.195028
Step: 33700, Train_loss:0.251959
Step: 33800, Train_loss:0.205211
Step: 33900, Train_loss:0.212338
Step: 34000, Train_loss:0.183795
Step: 34100, Train_loss:0.177731
Step: 34200, Train_loss:0.252747
Step: 34300, Train_loss:0.216758
Step: 34400, Train_loss:0.217104
Step: 34500, Train_loss:0.180558
Step: 34600, Train_loss:0.200747
Step: 34700, Train_loss:0.238034
Step: 34800, Train_loss:0.181356
Step: 34900, Train_loss:0.290979
Step: 35000, Train_loss:0.240827
2018-10-24 01:02:09.645167 ---> Validation_loss: 0.267281
Step: 35100, Train_loss:0.2397
Step: 35200, Train_loss:0.150978
Step: 35300, Train_loss:0.194203
Step: 35400, Train_loss:0.255661
Step: 35500, Train_loss:0.205225
Step: 35600, Train_loss:0.233437
Step: 35700, Train_loss:0.193987
Step: 35800, Train_loss:0.202083
Step: 35900, Train_loss:0.195736
Step: 36000, Train_loss:0.222948
Step: 36100, Train_loss:0.201874
Step: 36200, Train_loss:0.271955
Step: 36300, Train_loss:0.215342
Step: 36400, Train_loss:0.236476
Step: 36500, Train_loss:0.195088
Step: 36600, Train_loss:0.202735
Step: 36700, Train_loss:0.241059
Step: 36800, Train_loss:0.25359
Step: 36900, Train_loss:0.225484
Step: 37000, Train_loss:0.216108
Step: 37100, Train_loss:0.221614
Step: 37200, Train_loss:0.230612
Step: 37300, Train_loss:0.204415
Step: 37400, Train_loss:0.193438
Step: 37500, Train_loss:0.190499
Step: 37600, Train_loss:0.183977
Step: 37700, Train_loss:0.224637
Step: 37800, Train_loss:0.182305
Step: 37900, Train_loss:0.266373
Step: 38000, Train_loss:0.192843
Step: 38100, Train_loss:0.17268
Step: 38200, Train_loss:0.216564
Step: 38300, Train_loss:0.198866
Step: 38400, Train_loss:0.192923
Step: 38500, Train_loss:0.192951
Step: 38600, Train_loss:0.27923
Step: 38700, Train_loss:0.152253
Step: 38800, Train_loss:0.28426
Step: 38900, Train_loss:0.175237
Step: 39000, Train_loss:0.180225
Step: 39100, Train_loss:0.202403
****************** Epochs completed: 50******************
Step: 39200, Train_loss:0.289425
Step: 39300, Train_loss:0.188756
Step: 39400, Train_loss:0.174076
Step: 39500, Train_loss:0.172381
Step: 39600, Train_loss:0.198226
Step: 39700, Train_loss:0.140118
Step: 39800, Train_loss:0.179356
Step: 39900, Train_loss:0.188407
Step: 40000, Train_loss:0.227033
2018-10-24 01:29:26.458865 ---> Validation_loss: 0.263277
Step: 40100, Train_loss:0.200362
Step: 40200, Train_loss:0.227673
Step: 40300, Train_loss:0.249014
Step: 40400, Train_loss:0.198634
Step: 40500, Train_loss:0.200364
Step: 40600, Train_loss:0.1915
Step: 40700, Train_loss:0.193308
Step: 40800, Train_loss:0.214293
Step: 40900, Train_loss:0.228242
Step: 41000, Train_loss:0.185309
Step: 41100, Train_loss:0.25827
Step: 41200, Train_loss:0.174254
Step: 41300, Train_loss:0.200053
Step: 41400, Train_loss:0.195336
Step: 41500, Train_loss:0.217155
Step: 41600, Train_loss:0.226116
Step: 41700, Train_loss:0.189841
Step: 41800, Train_loss:0.199839
Step: 41900, Train_loss:0.239941
Step: 42000, Train_loss:0.259055
Step: 42100, Train_loss:0.191924
Step: 42200, Train_loss:0.23371
Step: 42300, Train_loss:0.210638
Step: 42400, Train_loss:0.279379
Step: 42500, Train_loss:0.21874
Step: 42600, Train_loss:0.207798
Step: 42700, Train_loss:0.180987
Step: 42800, Train_loss:0.216987
Step: 42900, Train_loss:0.197097
Step: 43000, Train_loss:0.189172
Step: 43100, Train_loss:0.215378
Step: 43200, Train_loss:0.19134
Step: 43300, Train_loss:0.167613
Step: 43400, Train_loss:0.170378
Step: 43500, Train_loss:0.182384
Step: 43600, Train_loss:0.233467
Step: 43700, Train_loss:0.166562
Step: 43800, Train_loss:0.252788
Step: 43900, Train_loss:0.195511
Step: 44000, Train_loss:0.266221
Step: 44100, Train_loss:0.211073
Step: 44200, Train_loss:0.20654
Step: 44300, Train_loss:0.208871
Step: 44400, Train_loss:0.198172
Step: 44500, Train_loss:0.188479
Step: 44600, Train_loss:0.186399
Step: 44700, Train_loss:0.202031
Step: 44800, Train_loss:0.207482
Step: 44900, Train_loss:0.17218
Step: 45000, Train_loss:0.200306
2018-10-24 01:56:41.536020 ---> Validation_loss: 0.277494
Step: 45100, Train_loss:0.167474
Step: 45200, Train_loss:0.229347
Step: 45300, Train_loss:0.175539
Step: 45400, Train_loss:0.26983
Step: 45500, Train_loss:0.219481
Step: 45600, Train_loss:0.236742
Step: 45700, Train_loss:0.188771
Step: 45800, Train_loss:0.255829
Step: 45900, Train_loss:0.231417
Step: 46000, Train_loss:0.253979
Step: 46100, Train_loss:0.175627
Step: 46200, Train_loss:0.187948
Step: 46300, Train_loss:0.264639
Step: 46400, Train_loss:0.171739
Step: 46500, Train_loss:0.206075
Step: 46600, Train_loss:0.187554
Step: 46700, Train_loss:0.18779
Step: 46800, Train_loss:0.211205
Step: 46900, Train_loss:0.216838
Step: 47000, Train_loss:0.231041
****************** Epochs completed: 60******************
Step: 47100, Train_loss:0.175698
Step: 47200, Train_loss:0.174739
Step: 47300, Train_loss:0.237131
Step: 47400, Train_loss:0.210921
Step: 47500, Train_loss:0.196074
Step: 47600, Train_loss:0.214926
Step: 47700, Train_loss:0.206917
Step: 47800, Train_loss:0.200971
Step: 47900, Train_loss:0.202854
Step: 48000, Train_loss:0.182992
Step: 48100, Train_loss:0.203072
Step: 48200, Train_loss:0.218718
Step: 48300, Train_loss:0.242233
Step: 48400, Train_loss:0.157711
Step: 48500, Train_loss:0.219219
Step: 48600, Train_loss:0.199789
Step: 48700, Train_loss:0.181709
Step: 48800, Train_loss:0.196129
Step: 48900, Train_loss:0.215852
Step: 49000, Train_loss:0.232166
Step: 49100, Train_loss:0.265196
Step: 49200, Train_loss:0.18646
Step: 49300, Train_loss:0.178761
Step: 49400, Train_loss:0.208272
Step: 49500, Train_loss:0.203618
Step: 49600, Train_loss:0.201942
Step: 49700, Train_loss:0.181478
Step: 49800, Train_loss:0.187464
Step: 49900, Train_loss:0.201818
Step: 50000, Train_loss:0.172589
2018-10-24 02:24:00.632328 ---> Validation_loss: 0.282416
****************** Epochs completed: 10******************
Step: 50100, Train_loss:0.252413
Step: 50200, Train_loss:0.142037
Step: 50300, Train_loss:0.188838
Step: 50400, Train_loss:0.263059
Step: 50500, Train_loss:0.195381
Step: 50600, Train_loss:0.213485
Step: 50700, Train_loss:0.198859
Step: 50800, Train_loss:0.12311
Step: 50900, Train_loss:0.190454
Step: 51000, Train_loss:0.216147
Step: 51100, Train_loss:0.18825
Step: 51200, Train_loss:0.191443
Step: 51300, Train_loss:0.173379
Step: 51400, Train_loss:0.170962
Step: 51500, Train_loss:0.258953
Step: 51600, Train_loss:0.20437
Step: 51700, Train_loss:0.213612
Step: 51800, Train_loss:0.182483
Step: 51900, Train_loss:0.203479
Step: 52000, Train_loss:0.246685
Step: 52100, Train_loss:0.166079
Step: 52200, Train_loss:0.222058
Step: 52300, Train_loss:0.225257
Step: 52400, Train_loss:0.207101
Step: 52500, Train_loss:0.139797
Step: 52600, Train_loss:0.175704
Step: 52700, Train_loss:0.25305
Step: 52800, Train_loss:0.222066
Step: 52900, Train_loss:0.188775
Step: 53000, Train_loss:0.220687
Step: 53100, Train_loss:0.1659
Step: 53200, Train_loss:0.225399
Step: 53300, Train_loss:0.23202
Step: 53400, Train_loss:0.181249
Step: 53500, Train_loss:0.250604
Step: 53600, Train_loss:0.249218
Step: 53700, Train_loss:0.151247
Step: 53800, Train_loss:0.117194
Step: 53900, Train_loss:0.25107
Step: 54000, Train_loss:0.189654
Step: 54100, Train_loss:0.137587
Step: 54200, Train_loss:0.180188
Step: 54300, Train_loss:0.223271
Step: 54400, Train_loss:0.168596
Step: 54500, Train_loss:0.201926
Step: 54600, Train_loss:0.245241
Step: 54700, Train_loss:0.19826
Step: 54800, Train_loss:0.198474
****************** Epochs completed: 70******************
Step: 54900, Train_loss:0.224586
Step: 55000, Train_loss:0.186138
2018-10-24 02:51:19.573475 ---> Validation_loss: 0.29127
Step: 55100, Train_loss:0.224177
Step: 55200, Train_loss:0.196228
Step: 55300, Train_loss:0.196741
Step: 55400, Train_loss:0.182826
Step: 55500, Train_loss:0.21845
Step: 55600, Train_loss:0.200463
Step: 55700, Train_loss:0.192435
Step: 55800, Train_loss:0.193301
Step: 55900, Train_loss:0.175711
Step: 56000, Train_loss:0.198029
Step: 56100, Train_loss:0.205772
Step: 56200, Train_loss:0.171349
Step: 56300, Train_loss:0.195512
Step: 56400, Train_loss:0.186696
Step: 56500, Train_loss:0.202495
Step: 56600, Train_loss:0.219789
Step: 56700, Train_loss:0.161883
Step: 56800, Train_loss:0.193941
Step: 56900, Train_loss:0.196872
Step: 57000, Train_loss:0.253374
Step: 57100, Train_loss:0.182529
Step: 57200, Train_loss:0.208608
Step: 57300, Train_loss:0.181937
Step: 57400, Train_loss:0.203175
Step: 57500, Train_loss:0.241735
Step: 57600, Train_loss:0.155045
Step: 57700, Train_loss:0.1633
Step: 57800, Train_loss:0.209032
Step: 57900, Train_loss:0.19517
Step: 58000, Train_loss:0.180944
Step: 58100, Train_loss:0.191416
Step: 58200, Train_loss:0.222671
Step: 58300, Train_loss:0.196808
Step: 58400, Train_loss:0.168947
Step: 58500, Train_loss:0.223509
Step: 58600, Train_loss:0.205697
Step: 58700, Train_loss:0.233154
Step: 58800, Train_loss:0.161213
Step: 58900, Train_loss:0.156447
Step: 59000, Train_loss:0.24133
Step: 59100, Train_loss:0.169359
Step: 59200, Train_loss:0.220469
Step: 59300, Train_loss:0.184396
Step: 59400, Train_loss:0.255323
Step: 59500, Train_loss:0.173165
Step: 59600, Train_loss:0.256579
Step: 59700, Train_loss:0.185516
Step: 59800, Train_loss:0.208787
Step: 59900, Train_loss:0.197223
Step: 60000, Train_loss:0.197058
2018-10-24 03:18:32.849077 ---> Validation_loss: 0.276206
Step: 60100, Train_loss:0.235194
Step: 60200, Train_loss:0.245774
Step: 60300, Train_loss:0.209305
Step: 60400, Train_loss:0.188149
Step: 60500, Train_loss:0.169029
Step: 60600, Train_loss:0.175406
Step: 60700, Train_loss:0.117788
Step: 60800, Train_loss:0.22612
Step: 60900, Train_loss:0.181397
Step: 61000, Train_loss:0.215748
Step: 61100, Train_loss:0.269367
Step: 61200, Train_loss:0.210552
Step: 61300, Train_loss:0.19396
Step: 61400, Train_loss:0.210842
Step: 61500, Train_loss:0.135022
Step: 61600, Train_loss:0.188239
Step: 61700, Train_loss:0.174643
Step: 61800, Train_loss:0.182948
Step: 61900, Train_loss:0.246604
Step: 62000, Train_loss:0.174303
Step: 62100, Train_loss:0.164547
Step: 62200, Train_loss:0.192366
Step: 62300, Train_loss:0.182383
Step: 62400, Train_loss:0.229061
Step: 62500, Train_loss:0.241899
Step: 62600, Train_loss:0.159276
Step: 62700, Train_loss:0.160647
****************** Epochs completed: 80******************
Step: 62800, Train_loss:0.191317
Step: 62900, Train_loss:0.219466
Step: 63000, Train_loss:0.182943
Step: 63100, Train_loss:0.155216
Step: 63200, Train_loss:0.19488
Step: 63300, Train_loss:0.184502
Step: 63400, Train_loss:0.191673
Step: 63500, Train_loss:0.184376
Step: 63600, Train_loss:0.222502
Step: 63700, Train_loss:0.174816
Step: 63800, Train_loss:0.225594
Step: 63900, Train_loss:0.213834
Step: 64000, Train_loss:0.19411
Step: 64100, Train_loss:0.223071
Step: 64200, Train_loss:0.238213
Step: 64300, Train_loss:0.143532
Step: 64400, Train_loss:0.16823
Step: 64500, Train_loss:0.2014
Step: 64600, Train_loss:0.245035
Step: 64700, Train_loss:0.221095
Step: 64800, Train_loss:0.196258
Step: 64900, Train_loss:0.183039
Step: 65000, Train_loss:0.19926
2018-10-24 03:45:47.987267 ---> Validation_loss: 0.294463
Step: 65100, Train_loss:0.210855
Step: 65200, Train_loss:0.206728
Step: 65300, Train_loss:0.211616
Step: 65400, Train_loss:0.220472
Step: 65500, Train_loss:0.262305
Step: 65600, Train_loss:0.19359
Step: 65700, Train_loss:0.193112
Step: 65800, Train_loss:0.176057
Step: 65900, Train_loss:0.199371
Step: 66000, Train_loss:0.244197
Step: 66100, Train_loss:0.216082
Step: 66200, Train_loss:0.18702
Step: 66300, Train_loss:0.173736
Step: 66400, Train_loss:0.167232
Step: 66500, Train_loss:0.190929
Step: 66600, Train_loss:0.188059
Step: 66700, Train_loss:0.183938
Step: 66800, Train_loss:0.183685
Step: 66900, Train_loss:0.167404
Step: 67000, Train_loss:0.218035
Step: 67100, Train_loss:0.174069
Step: 67200, Train_loss:0.20867
Step: 67300, Train_loss:0.201184
Step: 67400, Train_loss:0.195494
Step: 67500, Train_loss:0.148338
Step: 67600, Train_loss:0.187317
Step: 67700, Train_loss:0.216281
Step: 67800, Train_loss:0.193187
Step: 67900, Train_loss:0.179744
Step: 68000, Train_loss:0.20765
Step: 68100, Train_loss:0.192863
Step: 68200, Train_loss:0.184271
Step: 68300, Train_loss:0.153684
Step: 68400, Train_loss:0.222175
Step: 68500, Train_loss:0.17972
Step: 68600, Train_loss:0.181621
Step: 68700, Train_loss:0.191368
Step: 68800, Train_loss:0.177688
Step: 68900, Train_loss:0.217273
Step: 69000, Train_loss:0.238209
Step: 69100, Train_loss:0.193268
Step: 69200, Train_loss:0.237869
Step: 69300, Train_loss:0.190091
Step: 69400, Train_loss:0.189672
Step: 69500, Train_loss:0.163517
Step: 69600, Train_loss:0.187765
Step: 69700, Train_loss:0.114437
Step: 69800, Train_loss:0.244023
Step: 69900, Train_loss:0.114588
Step: 70000, Train_loss:0.181908
2018-10-24 04:13:05.241853 ---> Validation_loss: 0.315697
Step: 70100, Train_loss:0.20759
Step: 70200, Train_loss:0.162654
Step: 70300, Train_loss:0.207388
Step: 70400, Train_loss:0.161484
Step: 70500, Train_loss:0.190331
****************** Epochs completed: 90******************
Step: 70600, Train_loss:0.200647
Step: 70700, Train_loss:0.165393
Step: 70800, Train_loss:0.150745
Step: 70900, Train_loss:0.188882
Step: 71000, Train_loss:0.237074
Step: 71100, Train_loss:0.174448
Step: 71200, Train_loss:0.174287
Step: 71300, Train_loss:0.180374
Step: 71400, Train_loss:0.190792
Step: 71500, Train_loss:0.182788
Step: 71600, Train_loss:0.214795
Step: 71700, Train_loss:0.168912
Step: 71800, Train_loss:0.184905
Step: 71900, Train_loss:0.199199
Step: 72000, Train_loss:0.205852
Step: 72100, Train_loss:0.178664
Step: 72200, Train_loss:0.19781
Step: 72300, Train_loss:0.196993
Step: 72400, Train_loss:0.159902
Step: 72500, Train_loss:0.163693
Step: 72600, Train_loss:0.177597
Step: 72700, Train_loss:0.159341
Step: 72800, Train_loss:0.179726
Step: 72900, Train_loss:0.209968
Step: 73000, Train_loss:0.184562
Step: 73100, Train_loss:0.239945
Step: 73200, Train_loss:0.214705
Step: 73300, Train_loss:0.188479
Step: 73400, Train_loss:0.18798
Step: 73500, Train_loss:0.186588
Step: 73600, Train_loss:0.221661
Step: 73700, Train_loss:0.12681
Step: 73800, Train_loss:0.168855
Step: 73900, Train_loss:0.179056
Step: 74000, Train_loss:0.158912
Step: 74100, Train_loss:0.169074
Step: 74200, Train_loss:0.179506
Step: 74300, Train_loss:0.165717
Step: 74400, Train_loss:0.176781
Step: 74500, Train_loss:0.229868
Step: 74600, Train_loss:0.183978
Step: 74700, Train_loss:0.190547
Step: 74800, Train_loss:0.185716
Step: 74900, Train_loss:0.192844
Step: 75000, Train_loss:0.188768
2018-10-24 04:40:19.873956 ---> Validation_loss: 0.335383
Step: 75100, Train_loss:0.175313
Step: 75200, Train_loss:0.210514
Step: 75300, Train_loss:0.11142
Step: 75400, Train_loss:0.210268
Step: 75500, Train_loss:0.180014
Step: 75600, Train_loss:0.195091
Step: 75700, Train_loss:0.21401
Step: 75800, Train_loss:0.189245
Step: 75900, Train_loss:0.162828
Step: 76000, Train_loss:0.167647
Step: 76100, Train_loss:0.154659
Step: 76200, Train_loss:0.209704
Step: 76300, Train_loss:0.216605
Step: 76400, Train_loss:0.178347
Step: 76500, Train_loss:0.151592
Step: 76600, Train_loss:0.146029
Step: 76700, Train_loss:0.160338
Step: 76800, Train_loss:0.19833
Step: 76900, Train_loss:0.221372
Step: 77000, Train_loss:0.18673
Step: 77100, Train_loss:0.169583
Step: 77200, Train_loss:0.152917
Step: 77300, Train_loss:0.246567
Step: 77400, Train_loss:0.123979
Step: 77500, Train_loss:0.169419
Step: 77600, Train_loss:0.174695
Step: 77700, Train_loss:0.195993
Step: 77800, Train_loss:0.175955
Step: 77900, Train_loss:0.145412
Step: 78000, Train_loss:0.210085
Step: 78100, Train_loss:0.159603
Step: 78200, Train_loss:0.168267
Step: 78300, Train_loss:0.137738
****************** Epochs completed: 100******************
Step: 78400, Train_loss:0.114633
Step: 78500, Train_loss:0.174512
Step: 78600, Train_loss:0.20087
Step: 78700, Train_loss:0.148961
Step: 78800, Train_loss:0.164088
Step: 78900, Train_loss:0.1981
Step: 79000, Train_loss:0.179639
Step: 79100, Train_loss:0.242385
Step: 79200, Train_loss:0.174382
Step: 79300, Train_loss:0.16126
Step: 79400, Train_loss:0.226888
Step: 79500, Train_loss:0.125089
Step: 79600, Train_loss:0.167451
Step: 79700, Train_loss:0.251897
Step: 79800, Train_loss:0.165331
Step: 79900, Train_loss:0.127312
Step: 80000, Train_loss:0.239348
2018-10-24 05:07:32.557566 ---> Validation_loss: 0.34099
Step: 80100, Train_loss:0.150253
Step: 80200, Train_loss:0.22046
Step: 80300, Train_loss:0.164861
Step: 80400, Train_loss:0.189774
Step: 80500, Train_loss:0.178962
Step: 80600, Train_loss:0.1682
Step: 80700, Train_loss:0.167968
Step: 80800, Train_loss:0.15184
Step: 80900, Train_loss:0.157938
Step: 81000, Train_loss:0.176008
Step: 81100, Train_loss:0.174795
Step: 81200, Train_loss:0.17526
Step: 81300, Train_loss:0.171158
Step: 81400, Train_loss:0.16653
Step: 81500, Train_loss:0.204889
Step: 81600, Train_loss:0.237431
Step: 81700, Train_loss:0.184281
Step: 81800, Train_loss:0.161413
Step: 81900, Train_loss:0.189211
Step: 82000, Train_loss:0.229325
Step: 82100, Train_loss:0.212581
Step: 82200, Train_loss:0.167518
Step: 82300, Train_loss:0.195661
Step: 82400, Train_loss:0.165497
Step: 82500, Train_loss:0.183044
Step: 82600, Train_loss:0.196687
Step: 82700, Train_loss:0.149576
Step: 82800, Train_loss:0.162884
Step: 82900, Train_loss:0.228278
Step: 83000, Train_loss:0.225741
Step: 83100, Train_loss:0.238179
Step: 83200, Train_loss:0.17999
Step: 83300, Train_loss:0.16445
Step: 83400, Train_loss:0.225406
Step: 83500, Train_loss:0.187461
Step: 83600, Train_loss:0.241515
Step: 83700, Train_loss:0.227042
Step: 83800, Train_loss:0.173713
Step: 83900, Train_loss:0.177514
Step: 84000, Train_loss:0.236974
Step: 84100, Train_loss:0.179737
Step: 84200, Train_loss:0.175685
Step: 84300, Train_loss:0.165183
Step: 84400, Train_loss:0.199991
Step: 84500, Train_loss:0.168256
Step: 84600, Train_loss:0.165653
Step: 84700, Train_loss:0.156656
Step: 84800, Train_loss:0.167695
Step: 84900, Train_loss:0.174544
Step: 85000, Train_loss:0.136489
2018-10-24 05:34:45.068670 ---> Validation_loss: 0.348683
Step: 85100, Train_loss:0.181852
Step: 85200, Train_loss:0.199241
Step: 85300, Train_loss:0.178399
Step: 85400, Train_loss:0.178624
Step: 85500, Train_loss:0.175694
Step: 85600, Train_loss:0.156433
Step: 85700, Train_loss:0.204936
Step: 85800, Train_loss:0.158936
Step: 85900, Train_loss:0.108323
Step: 86000, Train_loss:0.166111
Step: 86100, Train_loss:0.147029
Step: 86200, Train_loss:0.171868
****************** Epochs completed: 110******************
Step: 86300, Train_loss:0.1399
Step: 86400, Train_loss:0.178554
Step: 86500, Train_loss:0.176709
Step: 86600, Train_loss:0.148928
Step: 86700, Train_loss:0.179983
Step: 86800, Train_loss:0.200986
Step: 86900, Train_loss:0.161187
Step: 87000, Train_loss:0.193641
Step: 87100, Train_loss:0.176222
Step: 87200, Train_loss:0.19893
Step: 87300, Train_loss:0.195382
Step: 87400, Train_loss:0.166855
Step: 87500, Train_loss:0.190045
Step: 87600, Train_loss:0.168246
Step: 87700, Train_loss:0.191755
Step: 87800, Train_loss:0.130707
Step: 87900, Train_loss:0.197164
Step: 88000, Train_loss:0.146388
Step: 88100, Train_loss:0.151133
Step: 88200, Train_loss:0.169081
Step: 88300, Train_loss:0.162864
Step: 88400, Train_loss:0.204056
Step: 88500, Train_loss:0.189724
Step: 88600, Train_loss:0.198552
Step: 88700, Train_loss:0.164052
Step: 88800, Train_loss:0.188359
Step: 88900, Train_loss:0.183625
Step: 89000, Train_loss:0.16732
Step: 89100, Train_loss:0.178227
Step: 89200, Train_loss:0.177208
Step: 89300, Train_loss:0.232361
Step: 89400, Train_loss:0.210991
Step: 89500, Train_loss:0.161626
Step: 89600, Train_loss:0.184026
Step: 89700, Train_loss:0.145429
Step: 89800, Train_loss:0.161867
Step: 89900, Train_loss:0.152497
Step: 90000, Train_loss:0.234218
2018-10-24 06:01:56.821582 ---> Validation_loss: 0.339761
Step: 90100, Train_loss:0.180319
Step: 90200, Train_loss:0.150144
Step: 90300, Train_loss:0.162123
Step: 90400, Train_loss:0.147911
Step: 90500, Train_loss:0.173981
Step: 90600, Train_loss:0.167161
Step: 90700, Train_loss:0.171207
Step: 90800, Train_loss:0.170856
Step: 90900, Train_loss:0.238352
Step: 91000, Train_loss:0.100786
Step: 91100, Train_loss:0.137427
Step: 91200, Train_loss:0.156497
Step: 91300, Train_loss:0.202814
Step: 91400, Train_loss:0.178514
Step: 91500, Train_loss:0.182621
Step: 91600, Train_loss:0.172096
Step: 91700, Train_loss:0.198285
Step: 91800, Train_loss:0.170993
Step: 91900, Train_loss:0.202803
Step: 92000, Train_loss:0.165933
Step: 92100, Train_loss:0.166191
Step: 92200, Train_loss:0.185235
Step: 92300, Train_loss:0.210713
Step: 92400, Train_loss:0.194961
Step: 92500, Train_loss:0.161681
Step: 92600, Train_loss:0.204601
Step: 92700, Train_loss:0.114635
Step: 92800, Train_loss:0.11734
Step: 92900, Train_loss:0.167161
Step: 93000, Train_loss:0.17619
Step: 93100, Train_loss:0.197096
Step: 93200, Train_loss:0.166458
Step: 93300, Train_loss:0.19824
Step: 93400, Train_loss:0.191272
Step: 93500, Train_loss:0.160436
Step: 93600, Train_loss:0.149845
Step: 93700, Train_loss:0.158436
Step: 93800, Train_loss:0.126739
Step: 93900, Train_loss:0.113175
Step: 94000, Train_loss:0.216311
****************** Epochs completed: 120******************
Step: 94100, Train_loss:0.156849
Step: 94200, Train_loss:0.172777
Step: 94300, Train_loss:0.138415
Step: 94400, Train_loss:0.19626
Step: 94500, Train_loss:0.178352
Step: 94600, Train_loss:0.16443
Step: 94700, Train_loss:0.147704
Step: 94800, Train_loss:0.194888
Step: 94900, Train_loss:0.202248
Step: 95000, Train_loss:0.166957
2018-10-24 06:29:09.986686 ---> Validation_loss: 0.342958
Step: 95100, Train_loss:0.186109
Step: 95200, Train_loss:0.17476
Step: 95300, Train_loss:0.171388
Step: 95400, Train_loss:0.192711
Step: 95500, Train_loss:0.152502
Step: 95600, Train_loss:0.147246
Step: 95700, Train_loss:0.172745
Step: 95800, Train_loss:0.201189
Step: 95900, Train_loss:0.196832
Step: 96000, Train_loss:0.15644
Step: 96100, Train_loss:0.176359
Step: 96200, Train_loss:0.155295
Step: 96300, Train_loss:0.192234
Step: 96400, Train_loss:0.162359
Step: 96500, Train_loss:0.111622
Step: 96600, Train_loss:0.171301
Step: 96700, Train_loss:0.232327
Step: 96800, Train_loss:0.15331
Step: 96900, Train_loss:0.146887
Step: 97000, Train_loss:0.1767
Step: 97100, Train_loss:0.196769
Step: 97200, Train_loss:0.191163
Step: 97300, Train_loss:0.166009
Step: 97400, Train_loss:0.195496
Step: 97500, Train_loss:0.149192
Step: 97600, Train_loss:0.172402
Step: 97700, Train_loss:0.183929
Step: 97800, Train_loss:0.130625
Step: 97900, Train_loss:0.184219
Step: 98000, Train_loss:0.164024
Step: 98100, Train_loss:0.201775
Step: 98200, Train_loss:0.134903
Step: 98300, Train_loss:0.137104
Step: 98400, Train_loss:0.156354
Step: 98500, Train_loss:0.161768
Step: 98600, Train_loss:0.162933
Step: 98700, Train_loss:0.155439
Step: 98800, Train_loss:0.210261
Step: 98900, Train_loss:0.170528
Step: 99000, Train_loss:0.165351
Step: 99100, Train_loss:0.184936
Step: 99200, Train_loss:0.149313
Step: 99300, Train_loss:0.223058
Step: 99400, Train_loss:0.159367
Step: 99500, Train_loss:0.189909
Step: 99600, Train_loss:0.185553
Step: 99700, Train_loss:0.150598
Step: 99800, Train_loss:0.189086
Step: 99900, Train_loss:0.215618
Step: 100000, Train_loss:0.193091
2018-10-24 06:56:22.018542 ---> Validation_loss: 0.373577
